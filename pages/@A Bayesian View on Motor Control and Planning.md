date:: 2010
publisher:: Springer Berlin Heidelberg
place:: "Berlin, Heidelberg"
isbn:: 978-3-642-05180-7 978-3-642-05181-4
doi:: 10.1007/978-3-642-05181-4_11
title:: @A Bayesian View on Motor Control and Planning
pages:: 227-252
volume:: 264
item-type:: [[conferencePaper]]
access-date:: 2025-02-06T09:32:06Z
original-title:: A Bayesian View on Motor Control and Planning
url:: http://link.springer.com/10.1007/978-3-642-05181-4_11
authors:: [[Marc Toussaint]], [[Christian Goerick]]
library-catalog:: Semantic Scholar
links:: [Local library](zotero://select/library/items/G8GIKLWP), [Web library](https://www.zotero.org/users/12562648/items/G8GIKLWP)

- [[Abstract]]
	- The problem of motion control and planning can be formulated as an optimization problem. In this paper we discuss an alternative view that casts the problem as one of probabilistic inference. In simple cases where the optimization problem can be solved analytically the inference view leads to equivalent solutions. However, when approximate methods are necessary to tackle the problem, the tight relation between optimization and probabilistic inference has fruitfully lead to a transfer of methods between both fields. Here we show that such a transfer is also possible in the realm of robotics. The general idea is that motion can be generated by fusing motion objectives (task constraints, goals, motion priors) by using probabilistic inference techniques. In realistic scenarios exact inference is infeasible (as is the analytic solution of the corresponding optimization problem) and the use of efficient approximate inference methods is a promising alternative to classical motion optimization methods. In this paper we first derive Bayesian control methods that are directly analogous to classical redundant motion rate control and optimal dynamic control (including operational space control). Then, by extending the probabilistic models to be Markovian models of the whole trajectory, we show that approximate probabilistic inference methods (message passing) efficiently compute solutions to trajectory optimization problems. Using Gaussian belief approximations and local linearization the algorithm becomes related to Differential Dynamic Programming (DDP) (aka. iterative Linear Quadratic Gaussian (iLQG)).
- [[Attachments]]
	- [PDF](zotero://select/library/items/NDAB8J3I) {{zotero-imported-file NDAB8J3I, "Toussaint and Goerick - 2010 - A Bayesian View on Motor Control and Planning.pdf"}}
	- [Semantic Scholar Link](https://www.semanticscholar.org/paper/A-Bayesian-View-on-Motor-Control-and-Planning-Toussaint-Goerick/74f7a802056c5ed6fae3a0ecca08ee2307ef3e3c)
- [[Заметки]]
	- [TLDR] This paper derives Bayesian control methods that are directly analogous to classical redundant motion rate control and optimal dynamic control (including operational space control) and shows that approximate probabilistic inference methods (message passing) efficiently compute solutions to trajectory optimization problems.